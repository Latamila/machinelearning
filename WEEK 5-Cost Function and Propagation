#A small value for {\epsilon}ϵ (epsilon) such as {\epsilon = 10^{-4}}ϵ=10 
#−4
# , guarantees that the math works out properly. If the value for \epsilonϵ is too small, we can end up with numerical problems. 
#
#Hence, we are only adding or subtracting epsilon to the \Theta_j matrix. In octave we can do it as follows:


epsilon = 1e-4;
for i = 1:n,
  thetaPlus = theta;
  thetaPlus(i) += epsilon;
  thetaMinus = theta;
  thetaMinus(i) -= epsilon;
  gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*epsilon)
end;

#We previously saw how to calculate the deltaVector. So once we compute our gradApprox vector, we can check that gradApprox ≈ deltaVector. 
#Once you have verified once that your backpropagation algorithm is correct, you don't need to compute gradApprox again. The code to compute gradApprox can be very slow.


#RANDOM INITIALIZATION: SIMMETRY BREAKING

Theta1=rand(10,11)*(2*EPSILON)- EPSILON;
Theta2=rand(1,11)*(2*EPSILON)- EPSILON;

#If the dimensions of Theta1 is 10x11, Theta2 is 10x11 and Theta3 is 1x11.

Theta1 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;
Theta2 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;
Theta3 = rand(1,11) * (2 * INIT_EPSILON) - INIT_EPSILON;

#rand(x,y) is just a function in octave that will initialize a matrix of random real numbers between 0 and 1. 
#(Note: the epsilon used above is unrelated to the epsilon from Gradient Checking)

#PUTTING IT TOGETHER

#First, pick a network architecture; choose the layout of your neural network, including how many hidden units in each layer and how many layers in total you want to have.
#Number of input units = dimension of features x^{(i)}x (i)
 

#Number of output units = number of classes

#Number of hidden units per layer = usually more the better (must balance with cost of computation as it increases with more hidden units)

#Defaults: 1 hidden layer. If you have more than 1 hidden layer, then it is recommended that you have the same number of units in every hidden layer.

#Training a Neural Network

#Randomly initialize the weights

#Implement forward propagation to get h_\Theta(x^{(i)})h Θ​(x (i)) for any x^{(i)}x (i)
 

#Implement the cost function

#Implement backpropagation to compute partial derivatives

#Use gradient checking to confirm that your backpropagation works. Then disable gradient checking.

#Use gradient descent or a built-in optimization function to minimize the cost function with the weights in theta.

#When we perform forward and back propagation, we loop on every training example:

for i = 1:m,
   Perform forward propagation and backpropagation using example (x(i),y(i))
   (Get activations a(l) and delta terms d(l) for l = 2,...,L
   
#Ideally, you want h_\Theta(x^{(i)})h Θ​(x (i)) \approx≈ y^{(i)}y (i)
#This will minimize our cost function. However, keep in mind that J(\Theta)J(Θ) is not convex and thus we can end up in a local minimum instead.    

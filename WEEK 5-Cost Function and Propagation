#A small value for {\epsilon}ϵ (epsilon) such as {\epsilon = 10^{-4}}ϵ=10 
#−4
# , guarantees that the math works out properly. If the value for \epsilonϵ is too small, we can end up with numerical problems. 
#
#Hence, we are only adding or subtracting epsilon to the \Theta_j matrix. In octave we can do it as follows:


epsilon = 1e-4;
for i = 1:n,
  thetaPlus = theta;
  thetaPlus(i) += epsilon;
  thetaMinus = theta;
  thetaMinus(i) -= epsilon;
  gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*epsilon)
end;

#We previously saw how to calculate the deltaVector. So once we compute our gradApprox vector, we can check that gradApprox ≈ deltaVector. 
#Once you have verified once that your backpropagation algorithm is correct, you don't need to compute gradApprox again. The code to compute gradApprox can be very slow.
